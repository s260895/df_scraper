{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alternate-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbselenium.tbdriver import TorBrowserDriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "discrete-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"jheronimus\"\n",
    "PASSWORD = \"dataforensics\"\n",
    "PASSCODE = \"8899\"\n",
    "\n",
    "# Databse\n",
    "DATABASE_NAME = \"silkroad\"\n",
    "LISTINGS_COLLECTION_NAME = \"lists\"\n",
    "HTML_PAGES_COLLECTION_NAME = \"html\"\n",
    "\n",
    "# Settings\n",
    "PAGES_NUMBER = 2\n",
    "\n",
    "# URLS\n",
    "ALTERNATE_URLS = ['http://silkroad4ow7pliq.onion',\n",
    "                 \"http://silkroad4uqi7hey.onion\"]\n",
    "\n",
    "URL = ALTERNATE_URLS[1]\n",
    "URL_LOGIN = URL + \"/?login\"\n",
    "# URL_CAPTCHA = URL + \"challenge.php\"\n",
    "\n",
    "\n",
    "# #log in and solve captcha\n",
    "\n",
    "def visit_and_login(driver):\n",
    "    \n",
    "    \n",
    "    #driver.get(URL_CAPTCHA)\n",
    "    \n",
    "    \n",
    "    driver.get(URL_LOGIN)\n",
    "\n",
    "    # Log in and solve the captcha\n",
    "    #WebDriverWait(driver, 120).until(EC.title_contains(\"login\"))\n",
    "    user_field = driver.find_element_by_name(\"username\")\n",
    "    pass_field = driver.find_element_by_name(\"password\")\n",
    "    #login_button = driver.find_element_by_name('login')\n",
    "    \n",
    "    user_field.send_keys(USERNAME)\n",
    "    time.sleep(2)\n",
    "    pass_field.send_keys(PASSWORD)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #login_button.click()\n",
    "    \n",
    "    WebDriverWait(driver, 120)\n",
    "    \n",
    "    \n",
    "    return driver\n",
    "\n",
    "#go trough pages and store information\n",
    "def get_pages(driver):\n",
    "    print(\"Starting the crawling\")\n",
    "    for i in range(1, PAGES_NUMBER + 1):\n",
    "        site_page = URL + '/?road=&reqpage=' + str(i)\n",
    "        driver.get(site_page)\n",
    "        filename = 'silkroad/'+ str(i) + '.html'\n",
    "        with open(\"/home/levi/silkroad/\" + \"filename\", \"w\") as f:\n",
    "            f.write(driver.page_source)\n",
    "            print('dowloaded 1 page')\n",
    "        #walk_through_pages(driver, site_page, db)\n",
    "    \n",
    "\n",
    "\n",
    "# def walk_through_pages(driver, site_page, db):\n",
    "#     posts_collection = db[LISTINGS_COLLECTION_NAME]\n",
    "#     html_collection = db[HTML_PAGES_COLLECTION_NAME]\n",
    "#     print(\"Loading:\", site_page)\n",
    "#     driver.get(site_page)\n",
    "# #     page_urls = get_page_urls(driver.page_source)\n",
    "# #     for page in page_urls:\n",
    "# #         print(\"Parsing:\", page)\n",
    "# #         driver.get(URL + \"forum/\" + page + \"page-1\")\n",
    "# #         # Number of pages in the thread\n",
    "# #         pages_total = get_n_pages(driver.page_source)\n",
    "\n",
    "#     for i in range(1, PAGES_NUMBER + 1):\n",
    "#         # Loads the page and stores it in the database as well as the data\n",
    "#         print(\"Parsing:\", site_page + str(i))\n",
    "#         driver.get(URL + '/?road=&reqpage=' + str(i))\n",
    "#         html = driver.page_source\n",
    "#         hashed_html = hasher(html)\n",
    "#         store_html(html, hashed_html, html_collection)\n",
    "\n",
    "# def store_html(html, html_hashed, collection):\n",
    "#     print(\"Inserting the page as html and hash in the database.\")\n",
    "#     page = { \"html_source\":html,\n",
    "#         \"html_hashed\":html_hashed}\n",
    "#     doc_id = collection.insert_one(page)\n",
    "\n",
    "\n",
    "# ##Calculates the hash of the data \n",
    "\n",
    "# def hasher(data):\n",
    "#     h = hashlib.sha256()\n",
    "#     data = data.encode('utf-8')\n",
    "#     h.update(data)\n",
    "#     return h.hexdigest()\n",
    "\n",
    "\n",
    "# #Initializes the connection to the database\n",
    "# def connect2mongo():\n",
    "#     #db = MongoClient(\"mongodb://localhost:27017/\")[DATABASE_NAME]\n",
    "#     uri = \"mongodb+srv://cluster0.vpvgy.mongodb.net/myFirstDatabase?authSource=%24external&authMechanism=MONGODB-X509&retryWrites=true&w=majority\"\n",
    "#     db = MongoClient(uri,\n",
    "#                      tls=True,\n",
    "#                      tlsCertificateKeyFile='/home/levi/X509-cert-4208623596569133477.pem')[DATABASE_NAME]\n",
    "#     return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "convertible-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the crawling\n",
      "dowloaded 1 page\n",
      "dowloaded 1 page\n"
     ]
    }
   ],
   "source": [
    "#database = connect2mongo()\n",
    "with TorBrowserDriver(\"/home/levi/tor-browser_en-US/\") as driver:\n",
    "    driver = visit_and_login(driver)\n",
    "    get_pages(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
